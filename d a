[33mcommit afee2d3513c41371bd9d9c414bce0c46e62c5f34[m[33m ([m[1;36mHEAD[m[33m)[m
Author: Yerlan <yerlan.temir@btsdigital.kz>
Date:   Tue Jul 23 11:18:55 2019 +0600

    model with attention,have a bug with predicting only one value

[1mdiff --git a/decoder_weights b/decoder_weights[m
[1mindex 03bd321..e3f04ca 100644[m
Binary files a/decoder_weights and b/decoder_weights differ
[1mdiff --git a/encoder_weights b/encoder_weights[m
[1mindex 47f5cdb..61e82cf 100644[m
Binary files a/encoder_weights and b/encoder_weights differ
[1mdiff --git a/model_weights b/model_weights[m
[1mindex 65fdffd..aa69c6d 100644[m
Binary files a/model_weights and b/model_weights differ
[1mdiff --git a/temp.ipynb b/temp.ipynb[m
[1mindex cff93cc..b7c5c1c 100644[m
[1m--- a/temp.ipynb[m
[1m+++ b/temp.ipynb[m
[36m@@ -2,7 +2,7 @@[m
  "cells": [[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 6,[m
[32m+[m[32m   "execution_count": 2,[m
    "metadata": {[m
     "scrolled": true[m
    },[m
[36m@@ -17,16 +17,17 @@[m
     "import numpy as np\n",[m
     "import torch\n",[m
     "import torch.nn as nn\n",[m
[32m+[m[32m    "\n",[m
     "import torch.nn.functional as F\n",[m
     "import torch.optim as optim\n",[m
     "\n",[m
     "root_path = 'data/transcriptions'\n",[m
[31m-    "data_path = os.path.join(root_path,'train.csv')"[m
[32m+[m[32m    "data_path = os.path.join(root_path,'train.csv')\n"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 7,[m
[32m+[m[32m   "execution_count": 3,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -91,7 +92,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 256,[m
[32m+[m[32m   "execution_count": 4,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -193,7 +194,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 259,[m
[32m+[m[32m   "execution_count": 5,[m
    "metadata": {[m
     "scrolled": true[m
    },[m
[36m@@ -205,7 +206,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 260,[m
[32m+[m[32m   "execution_count": 6,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -228,7 +229,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 261,[m
[32m+[m[32m   "execution_count": 7,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -253,13 +254,13 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 262,[m
[32m+[m[32m   "execution_count": 8,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[31m-    "class DecoderLSTM(nn.Module):\n",[m
[32m+[m[32m    "class AttentionDecoderLSTM(nn.Module):\n",[m
     "    def __init__(self,embed_dim,hidden_size,output_size,n_layers=1,dropout=0):\n",[m
[31m-    "        super(DecoderLSTM,self).__init__()\n",[m
[32m+[m[32m    "        super(AttentionDecoderLSTM,self).__init__()\n",[m
     "        self.hidden_size = hidden_size\n",[m
     "        self.output_size = output_size\n",[m
     "        self.n_layers = n_layers\n",[m
[36m@@ -268,20 +269,40 @@[m
     "        #layers\n",[m
     "        self.embedding = nn.Embedding(output_size,embed_dim, padding_idx = 0)\n",[m
     "        self.LSTM = nn.LSTM(embed_dim,hidden_size,n_layers,dropout = (0 if n_layers == 1 else self.dropout),batch_first=True)\n",[m
[32m+[m[32m    "        self.concat = nn.Linear(hidden_size*2,hidden_size)\n",[m
     "        self.out = nn.Linear(hidden_size,output_size)\n",[m
     "        \n",[m
     "        \n",[m
[31m-    "    def forward(self,input_step,last_hidden):\n",[m
[32m+[m[32m    "    def forward(self,input_step,last_hidden,encoder_outputs):\n",[m
[32m+[m[32m    "        \n",[m
     "        #input_step (batch_size,seq_len)\n",[m
     "        embedded = self.embedding(input_step)\n",[m
     "        #embedded(batch_size,seq_len,hidden_dim)\n",[m
[31m-    "\n",[m
[31m-    "        output,hidden = self.LSTM(embedded,last_hidden)\n",[m
[31m-    "        #output(batch_size,seq_len,hidden_dim)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        decoder_outputs,hidden = self.LSTM(embedded,last_hidden)\n",[m
[32m+[m[32m    "        #(batch_size,decoder_seq_len,hidden_dim)\n",[m
     "        #seq_len = 1 if we using teacher forcing\n",[m
[31m-    "        #output = output.squeeze(1) #(batch_size,hidden_dim) for teacher forcing\n",[m
     "        \n",[m
[31m-    "        prediction = self.out(output)\n",[m
[32m+[m[32m    "        decoder_outputs = decoder_outputs.transpose(1,2)\n",[m
[32m+[m[32m    "        #(batch_size,hidden_dim,decoder_seq_len)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        attention_weights = encoder_outputs.bmm(decoder_outputs)\n",[m
[32m+[m[32m    "        #(batch_size,encoder_seq_len,decoder_seq_len)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        attention_weights = attention_weights.transpose(1,2)\n",[m
[32m+[m[32m    "        #(batch_size,decoder_seq_len,encoder_seq_len)\n",[m
[32m+[m[32m    "        attention_weights = F.softmax(attention_weights,dim=1)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        context_vector = attention_weights.bmm(encoder_outputs)\n",[m
[32m+[m[32m    "        #(batch_size,decoder_seq_len,hidden_dim)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        decoder_outputs = decoder_outputs.transpose(1,2)\n",[m
[32m+[m[32m    "        #(batch_size,decoder_seq_len,hidden_dim)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        concated = torch.cat((decoder_outputs,context_vector),2)\n",[m
[32m+[m[32m    "        concated_output = torch.tanh(self.concat(concated))\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        prediction = self.out(concated_output)\n",[m
     "        #prediction(seq_len,batch_size,output_dim) if no teacher_forcing\n",[m
     "        \n",[m
     "        return prediction,hidden"[m
[36m@@ -289,46 +310,58 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 263,[m
[32m+[m[32m   "execution_count": 9,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[31m-    "encoder = EncoderLSTM(32,64,len(dataset.characters_vocab)).to(device)"[m
[32m+[m[32m    "device = torch.device(\"cpu\")\n",[m
[32m+[m[32m    "BATCH_SIZE        = 32\n",[m
[32m+[m[32m    "HIDDEN_DIM        = 64\n",[m
[32m+[m[32m    "INPUT_VOCAB_SIZE  = len(dataset.characters_vocab)\n",[m
[32m+[m[32m    "OUTPUT_VOCAB_SIZE = len(dataset.transcripts_vocab)\n",[m
[32m+[m[32m    "encoder = EncoderLSTM(BATCH_SIZE,HIDDEN_DIM,INPUT_VOCAB_SIZE).to(device)\n",[m
[32m+[m[32m    "decoder = AttentionDecoderLSTM(BATCH_SIZE,HIDDEN_DIM,OUTPUT_VOCAB_SIZE).to(device)"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 264,[m
[32m+[m[32m   "execution_count": 11,[m
    "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "28"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 264,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[31m-    }[m
[31m-   ],[m
[32m+[m[32m   "outputs": [],[m
    "source": [[m
[31m-    "decoder = DecoderLSTM(32,64,len(dataset.transcripts_vocab)).to(device)\n",[m
[31m-    "len(dataset.characters_vocab)"[m
[32m+[m[32m    "for batch in dataloader:\n",[m
[32m+[m[32m    "    kek = batch\n",[m
[32m+[m[32m    "    break\n",[m
[32m+[m[32m    "x = kek[0].to(device)\n",[m
[32m+[m[32m    "x_lengths = kek[1]\n",[m
[32m+[m[32m    "y_in = kek[2].to(device)"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 265,[m
[32m+[m[32m   "execution_count": 13,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[31m-    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"[m
[32m+[m[32m    "encoder_outputs,encoder_hidden = encoder(x,x_lengths)\n",[m
[32m+[m[32m    "decoder_outputs = decoder(y_in,encoder_hidden)\n",[m
[32m+[m[32m    "at = decoder_outputs.bmm(encoder_outputs.transpose(1,2))"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 280,[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {[m
[32m+[m[32m    "scrolled": true[m
[32m+[m[32m   },[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "at2 = torch.sum(decoder_outputs*encoder_outputs,dim=2)"[m
[32m+[m[32m   ][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": 9,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -343,8 +376,8 @@[m
     "    \n",[m
     "    def forward(self,x,x_lengths,y,teacher_forcing_ratio = 0.3):\n",[m
     "        \n",[m
[31m-    "        encoder_output,hidden = self.encoder(x,x_lengths)\n",[m
[31m-    "        decoder_outputs,hidden = self.decoder(y,hidden)\n",[m
[32m+[m[32m    "        encoder_outputs,encoder_hidden = self.encoder(x,x_lengths)\n",[m
[32m+[m[32m    "        predictions,hidden = self.decoder(y,encoder_hidden,encoder_outputs)\n",[m
     "        \n",[m
     "       \n",[m
     "        #hidden = self.encoder(x)\n",[m
[36m@@ -357,85 +390,44 @@[m
     "            #top1 = output.max(1)[1]\n",[m
     "           # input_token = (y[:,t] if teacher_force else top1)\n",[m
     "        \n",[m
[31m-    "        return decoder_outputs\n",[m
[32m+[m[32m    "        return predictions\n",[m
     "    \n",[m
     "    def predict(self,x,x_lengths):\n",[m
     "        \n",[m
     "        #batch_size = 1!\n",[m
     "        x.unsqueeze_(0)\n",[m
     "        encoder_outputs,hidden = self.encoder(x,x_lengths)\n",[m
[31m-    "        char_to_input = torch.LongTensor([[2]]).to(device)\n",[m
[31m-    "        preds = []\n",[m
[32m+[m[32m    "        char_to_input = torch.LongTensor([[2]])\n",[m
[32m+[m[32m    "        preds = torch.tensor(char_to_input).to(self.device)\n",[m
[32m+[m[32m    "        \n",[m
     "        while True:\n",[m
[31m-    "            predictions, hidden = self.decoder(char_to_input, hidden)\n",[m
[32m+[m[32m    "            predictions,hidden = self.decoder(preds, hidden,encoder_outputs)\n",[m
     "            index_of_next = torch.argmax(predictions)\n",[m
     "            our_value = index_of_next.item()\n",[m
[32m+[m[32m    "\n",[m
     "            if our_value == 3:\n",[m
     "                break\n",[m
[31m-    "            preds.append(our_value)\n",[m
     "            char_to_input = index_of_next.unsqueeze_(0).unsqueeze_(0)\n",[m
[32m+[m[32m    "            preds = torch.cat((preds,char_to_input),1)\n",[m
     "        return preds"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 281,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [],[m
[31m-   "source": [[m
[31m-    "model = seq2seq(encoder,decoder,device).to(device)"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 282,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {[m
     "scrolled": true[m
    },[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "seq2seq(\n",[m
[31m-       "  (encoder): EncoderLSTM(\n",[m
[31m-       "    (embedding): Embedding(28, 32, padding_idx=0)\n",[m
[31m-       "    (LSTM): LSTM(32, 64, batch_first=True)\n",[m
[31m-       "  )\n",[m
[31m-       "  (decoder): DecoderLSTM(\n",[m
[31m-       "    (embedding): Embedding(28, 32, padding_idx=0)\n",[m
[31m-       "    (LSTM): LSTM(32, 64, batch_first=True)\n",[m
[31m-       "    (out): Linear(in_features=64, out_features=28, bias=True)\n",[m
[31m-       "  )\n",[m
[31m-       ")"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 282,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[31m-    }[m
[31m-   ],[m
[32m+[m[32m   "outputs": [],[m
    "source": [[m
[32m+[m[32m    "model = seq2seq(encoder,decoder,device)\n",[m
[32m+[m[32m    "\n",[m
     "def init_weights(m):\n",[m
     "    for name, param in m.named_parameters():\n",[m
     "        nn.init.uniform_(param.data, -0.08, 0.08)\n",[m
     "        \n",[m
[31m-    "model.apply(init_weights)"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 283,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "name": "stdout",[m
[31m-     "output_type": "stream",[m
[31m-     "text": [[m
[31m-      "The model has 53,788 trainable parameters\n"[m
[31m-     ][m
[31m-    }[m
[31m-   ],[m
[31m-   "source": [[m
[32m+[m[32m    "model.apply(init_weights)\n",[m
[32m+[m[32m    "\n",[m
     "def count_parameters(model):\n",[m
     "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",[m
     "\n",[m
[36m@@ -444,7 +436,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 284,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -454,7 +446,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 271,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -496,7 +488,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 272,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -530,7 +522,16 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 273,[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "x[0].shape"[m
[32m+[m[32m   ][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -545,29 +546,23 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 274,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "image/png": "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\n",[m
[31m-      "text/plain": [[m
[31m-       "<Figure size 432x288 with 1 Axes>"[m
[31m-      ][m
[31m-     },[m
[31m-     "metadata": {[m
[31m-      "needs_background": "light"[m
[31m-     },[m
[31m-     "output_type": "display_data"[m
[31m-    },[m
[31m-    {[m
[31m-     "name": "stdout",[m
[31m-     "output_type": "stream",[m
[31m-     "text": [[m
[31m-      "\tTrain Loss: 0.356 | Train PPL:   1.427\n"[m
[31m-     ][m
[31m-    }[m
[31m-   ],[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
    "source": [[m
     "import math\n",[m
     "\n",[m
[36m@@ -593,7 +588,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 275,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -604,20 +599,9 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 290,[m
[32m+[m[32m   "execution_count": 10,[m
    "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 290,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[31m-    }[m
[31m-   ],[m
[32m+[m[32m   "outputs": [],[m
    "source": [[m
     "encoder.load_state_dict(torch.load('encoder_weights'))\n",[m
     "decoder.load_state_dict(torch.load('decoder_weights'))\n",[m
[36m@@ -627,7 +611,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 300,[m
[32m+[m[32m   "execution_count": 18,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -638,27 +622,35 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 301,[m
[32m+[m[32m   "execution_count": 32,[m
    "metadata": {},[m
    "outputs": [[m
     {[m
      "data": {[m
       "text/plain": [[m
[31m-       "tensor([ 6, 21, 17, 21, 20, 21,  6, 21,  8,  8,  4,  0,  0,  0])"[m
[32m+[m[32m       "tensor([10, 24, 10, 18, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",[m
[32m+[m[32m       "         0])"[m
       ][m
      },[m
[31m-     "execution_count": 301,[m
[32m+[m[32m     "execution_count": 32,[m
      "metadata": {},[m
      "output_type": "execute_result"[m
     }[m
    ],[m
    "source": [[m
[31m-    "kek[0][1]"[m
[32m+[m[32m    "kek[0][31]"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 302,[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": 21,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -667,6 +659,7 @@[m
     "    y_tokens_predicted = []\n",[m
     "    y_tokens_true = []\n",[m
     "    for i in range(batch_size):\n",[m
[32m+[m[32m    "        print(i)\n",[m
     "        x_tokens.append(''.join([dataset.characters_vocab.idx2token(k.item()) for k in batch[0][i] if k.item() != 0]))\n",[m
     "        y_pred = model.predict(batch[0][i].to(device),[batch[1][i]])\n",[m
     "        y_tokens_predicted.append(''.join([dataset.transcripts_vocab.idx2token(k) for k in y_pred]))\n",[m
[36m@@ -682,27 +675,6 @@[m
    "execution_count": null,[m
    "metadata": {},[m
    "outputs": [],[m
[31m-   "source": [[m
[31m-    "predict_batch(model,kek,32)"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 574,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "('CATAWBA<pad><pad><pad><pad><pad><pad><pad>',\n",[m
[31m-       " '<sos>KAHTAOBAH<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>')"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 574,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[31m-    }[m
[31m-   ],[m
    "source": [[m
     "inp = ''\n",[m
     "out = ''\n",[m
[36m@@ -715,41 +687,78 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 476,[m
[32m+[m[32m   "execution_count": 22,[m
    "metadata": {},[m
    "outputs": [[m
     {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "torch.Size([18])"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 476,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[32m+[m[32m     "name": "stdout",[m
[32m+[m[32m     "output_type": "stream",[m
[32m+[m[32m     "text": [[m
[32m+[m[32m      "0\n"[m
[32m+[m[32m     ][m
[32m+[m[32m    },[m
[32m+[m[32m    {[m
[32m+[m[32m     "name": "stderr",[m
[32m+[m[32m     "output_type": "stream",[m
[32m+[m[32m     "text": [[m
[32m+[m[32m      "/home/yerlan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"[m
[32m+[m[32m     ][m
[32m+[m[32m    },[m
[32m+[m[32m    {[m
[32m+[m[32m     "ename": "RuntimeError",[m
[32m+[m[32m     "evalue": "index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191",[m
[32m+[m[32m     "output_type": "error",[m
[32m+[m[32m     "traceback": [[m
[32m+[m[32m      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",[m
[32m+[m[32m      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",[m
[32m+[m[32m      "\u001b[0;32m<ipython-input-22-afd31648ad14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkek\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",[m
[32m+[m[32m      "\u001b[0;32m<ipython-input-21-680436507667>\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(model, batch, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacters_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_tokens_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscripts_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_tokens_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscripts_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;32m<ipython-input-9-b1adb4eaf59e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, x_lengths)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mindex_of_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mour_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;32m<ipython-input-7-d36f5e1cfc30>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_step, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#input_step (batch_size,seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#embedded(batch_size,seq_len,hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m         return F.embedding(\n\u001b[1;32m    117\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",[m
[32m+[m[32m      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191"[m
[32m+[m[32m     ][m
     }[m
    ],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "predict_batch(model,kek,32)"[m
[32m+[m[32m   ][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "a = torch.argmax(predictions).unsqueeze_(0).unsqueeze_(0).shape"[m
[32m+[m[32m   ][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
    "source": [[m
     "kek[0][1]"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 460,[m
[32m+[m[32m   "execution_count": null,[m
    "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "ename": "NameError",[m
[31m-     "evalue": "name 'x_tokens' is not defined",[m
[31m-     "output_type": "error",[m
[31m-     "traceback": [[m
[31m-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",[m
[31m-      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",[m
[31m-      "\u001b[0;32m<ipython-input-460-2430716c7d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",[m
[31m-      "\u001b[0;31mNameError\u001b[0m: name 'x_tokens' is not defined"[m
[31m-     ][m
[31m-    }[m
[31m-   ],[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "yt.shape"[m
[32m+[m[32m   ][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
    "source": [[m
     "x_tokens"[m
    ][m
[36m@@ -760,6 +769,31 @@[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "predict_batch(model,kek,32)"[m
[32m+[m[32m   ][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [][m
[32m+[m[32m  },[m
[32m+[m[32m  {[m
[32m+[m[32m   "cell_type": "code",[m
[32m+[m[32m   "execution_count": null,[m
[32m+[m[32m   "metadata": {},[m
[32m+[m[32m   "outputs": [],[m
[32m+[m[32m   "source": [[m
[32m+[m[32m    "predict_batch(model,kek,32)"[m
[32m+[m[32m   ][m
   }[m
  ],[m
  "metadata": {[m
[36m@@ -778,7 +812,7 @@[m
    "name": "python",[m
    "nbconvert_exporter": "python",[m
    "pygments_lexer": "ipython3",[m
[31m-   "version": "3.7.3"[m
[32m+[m[32m   "version": "3.7.0"[m
   }[m
  },[m
  "nbformat": 4,[m
[1mdiff --git a/tut1-model.pt b/tut1-model.pt[m
[1mindex 65fdffd..b0bb2a3 100644[m
Binary files a/tut1-model.pt and b/tut1-model.pt differ

[33mcommit 4a818eaabf1f1dc189747571b2be03b08e4e98cb[m
Author: Yerlan <yerlan.temir@btsdigital.kz>
Date:   Sat Jul 20 19:34:49 2019 +0500

    docs(temp.ipynb):VANILLA seq2seq model by using pack padded seq,loss ~ 0.35

[1mdiff --git a/decoder_weights b/decoder_weights[m
[1mindex 5254775..03bd321 100644[m
Binary files a/decoder_weights and b/decoder_weights differ
[1mdiff --git a/encoder_weights b/encoder_weights[m
[1mindex 7f979a5..47f5cdb 100644[m
Binary files a/encoder_weights and b/encoder_weights differ
[1mdiff --git a/model_weights b/model_weights[m
[1mindex 5a76933..65fdffd 100644[m
Binary files a/model_weights and b/model_weights differ
[1mdiff --git a/temp.ipynb b/temp.ipynb[m
[1mindex f041d01..cff93cc 100644[m
[1m--- a/temp.ipynb[m
[1m+++ b/temp.ipynb[m
[36m@@ -2,7 +2,7 @@[m
  "cells": [[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 40,[m
[32m+[m[32m   "execution_count": 6,[m
    "metadata": {[m
     "scrolled": true[m
    },[m
[36m@@ -26,7 +26,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 41,[m
[32m+[m[32m   "execution_count": 7,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -91,7 +91,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 526,[m
[32m+[m[32m   "execution_count": 256,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -124,12 +124,15 @@[m
     "    def make_dataset(self):\n",[m
     "        characters = set()\n",[m
     "        transcripts = set()\n",[m
[32m+[m[32m    "        \n",[m
     "        for idx in range(len(self.file)):\n",[m
     "            item = str(self.file.iloc[idx][0]).split(',')\n",[m
     "            \n",[m
     "            x = item[1].strip()\n",[m
     "            for symbol in self.non_needed_symbols:\n",[m
     "                x = x.replace(symbol,'')\n",[m
[32m+[m[32m    "            if x == '':\n",[m
[32m+[m[32m    "                continue\n",[m
     "            y = item[2].replace(' ','')\n",[m
     "            self.data.append({'x':x,'y':y})\n",[m
     "            for character in x:\n",[m
[36m@@ -142,32 +145,38 @@[m
     "    \n",[m
     "            \n",[m
     "    def collate_fn(self, batch): \n",[m
[31m-    "        x_values = []\n",[m
[31m-    "        y_values_in = []\n",[m
[31m-    "        x_lengths = []\n",[m
[31m-    "        y_lengths = []\n",[m
[32m+[m[32m    "        x_values     =  []\n",[m
[32m+[m[32m    "        x_lengths    =  []\n",[m
[32m+[m[32m    "        y_values_in  =  []\n",[m
[32m+[m[32m    "        y_values_out =  []\n",[m
[32m+[m[32m    "        \n",[m
     "        for item in batch:\n",[m
     "            \n",[m
     "            x_values.append([self.characters_vocab.token2idx(ch) for ch in item['x']])\n",[m
     "            y_values_in.append([self.transcripts_vocab.token2idx(tr) for tr in item['y']])\n",[m
[32m+[m[32m    "            y_values_out.append([self.transcripts_vocab.token2idx(tr) for tr in item['y']])\n",[m
[32m+[m[32m    "            \n",[m
[32m+[m[32m    "        sorted_tuples = sorted(zip(x_values,y_values_in,y_values_out),key=lambda x:len(x[0]),reverse=True)\n",[m
[32m+[m[32m    "        x_values     =  [l[0] for l in sorted_tuples]\n",[m
[32m+[m[32m    "        y_values_in  =  [l[1] for l in sorted_tuples]\n",[m
[32m+[m[32m    "        y_values_out =  [l[2] for l in sorted_tuples]\n",[m
     "        \n",[m
[31m-    "        \n",[m
[31m-    "        max_x = len(max(x_values,key=len))\n",[m
[31m-    "        max_y = len(max(y_values_in,key=len))\n",[m
[31m-    "        \n",[m
[31m-    "        for word_index in range(len(x_values)):\n",[m
[32m+[m[32m    "        max_x = len(x_values[0])\n",[m
[32m+[m[32m    "        max_y = max(len(l) for l in y_values_in)\n",[m
     "            \n",[m
[31m-    "            x_lengths.append(len(x_values[word_index]))\n",[m
[31m-    "            y_lengths.append(len(y_values_in[word_index]))\n",[m
[32m+[m[32m    "        for word_index in range(len(x_values)):\n",[m
[32m+[m[32m    "            length_of_current_x = len(x_values[word_index])\n",[m
[32m+[m[32m    "            length_of_current_y = len(y_values_in[word_index])\n",[m
[32m+[m[32m    "\n",[m
[32m+[m[32m    "            x_lengths.append(length_of_current_x)\n",[m
     "            \n",[m
[31m-    "            for _ in range(1+ max_x - len(x_values[word_index])):\n",[m
[32m+[m[32m    "            for _ in range(1 +  max_x - length_of_current_x):\n",[m
     "                x_values[word_index].append(0)\n",[m
[31m-    "            for _ in range(1+ max_y - len(y_values_in[word_index])):\n",[m
[32m+[m[32m    "            for _ in range(1+ max_y - length_of_current_y):\n",[m
     "                y_values_in[word_index].append(0)\n",[m
     "            \n",[m
     "            y_values_in[word_index].insert(0,2)\n",[m
     "            \n",[m
[31m-    "        x_values = torch.tensor(x_values)\n",[m
     "        y_values_in_tensor = torch.tensor(y_values_in)\n",[m
     "        \n",[m
     "        y_values_out = y_values_in        \n",[m
[36m@@ -175,15 +184,16 @@[m
     "            index_of_first_zero = y_values_out[arr_index].index(0)\n",[m
     "            y_values_out[arr_index][index_of_first_zero] = 3\n",[m
     "            y_values_out[arr_index] = y_values_out[arr_index][1:]+[0]\n",[m
[31m-    "            \n",[m
[32m+[m[32m    "\n",[m
[32m+[m[32m    "        x_values_tensor     = torch.tensor(x_values)\n",[m
     "        y_values_out_tensor = torch.tensor(y_values_out)\n",[m
     "        \n",[m
[31m-    "        return x_values,y_values_in_tensor,y_values_out_tensor"[m
[32m+[m[32m    "        return x_values_tensor,x_lengths,y_values_in_tensor,y_values_out_tensor"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 527,[m
[32m+[m[32m   "execution_count": 259,[m
    "metadata": {[m
     "scrolled": true[m
    },[m
[36m@@ -195,18 +205,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 203,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [],[m
[31m-   "source": [[m
[31m-    "for kek in dataloader:\n",[m
[31m-    "    kek = kek\n",[m
[31m-    "    break"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 554,[m
[32m+[m[32m   "execution_count": 260,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -229,7 +228,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 555,[m
[32m+[m[32m   "execution_count": 261,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -240,17 +239,21 @@[m
     "        self.embedding = nn.Embedding(output_size,embed_dim,padding_idx = 0)\n",[m
     "        self.LSTM = nn.LSTM(embed_dim,hidden_size,n_layers,dropout=(0 if n_layers == 1 else dropout),batch_first=True)\n",[m
     "    \n",[m
[31m-    "    def forward(self,input_seq,hidden=None):\n",[m
[32m+[m[32m    "    def forward(self,input_seq,input_lengths,hidden=None):\n",[m
[32m+[m[32m    "        \n",[m
     "        embedded = self.embedding(input_seq)\n",[m
[31m-    "        #packed = nn.utils.rnn.pack_padded_sequence(embedded,input_lengths)\n",[m
[31m-    "        outputs,hidden = self.LSTM(embedded)\n",[m
[31m-    "        #outputs,_ = nn.utils.rnn.pad_packed_sequence(outputs)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        packed = nn.utils.rnn.pack_padded_sequence(embedded,input_lengths,batch_first=True)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        outputs,hidden = self.LSTM(packed)\n",[m
[32m+[m[32m    "        \n",[m
[32m+[m[32m    "        outputs,_ = nn.utils.rnn.pad_packed_sequence(outputs,batch_first=True)\n",[m
     "        return outputs,hidden"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 556,[m
[32m+[m[32m   "execution_count": 262,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -286,26 +289,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": null,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [],[m
[31m-   "source": [[m
[31m-    "hidden = encoder(kek[0].to(device))\n",[m
[31m-    "output,hidden = decoder(kek[1].to(device),hidden)"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": null,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [],[m
[31m-   "source": [[m
[31m-    "hidden.shape"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 557,[m
[32m+[m[32m   "execution_count": 263,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -314,7 +298,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 558,[m
[32m+[m[32m   "execution_count": 264,[m
    "metadata": {},[m
    "outputs": [[m
     {[m
[36m@@ -323,7 +307,7 @@[m
        "28"[m
       ][m
      },[m
[31m-     "execution_count": 558,[m
[32m+[m[32m     "execution_count": 264,[m
      "metadata": {},[m
      "output_type": "execute_result"[m
     }[m
[36m@@ -335,7 +319,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 559,[m
[32m+[m[32m   "execution_count": 265,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -344,7 +328,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 560,[m
[32m+[m[32m   "execution_count": 280,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -356,9 +340,10 @@[m
     "        self.decoder = decoder\n",[m
     "        self.device = device\n",[m
     "    \n",[m
[31m-    "    def forward(self,x,y,teacher_forcing_ratio = 0.3):\n",[m
[32m+[m[32m    "    \n",[m
[32m+[m[32m    "    def forward(self,x,x_lengths,y,teacher_forcing_ratio = 0.3):\n",[m
     "        \n",[m
[31m-    "        encoder_output,hidden = self.encoder(x)\n",[m
[32m+[m[32m    "        encoder_output,hidden = self.encoder(x,x_lengths)\n",[m
     "        decoder_outputs,hidden = self.decoder(y,hidden)\n",[m
     "        \n",[m
     "       \n",[m
[36m@@ -374,11 +359,11 @@[m
     "        \n",[m
     "        return decoder_outputs\n",[m
     "    \n",[m
[31m-    "    def predict(self,x):\n",[m
[32m+[m[32m    "    def predict(self,x,x_lengths):\n",[m
     "        \n",[m
     "        #batch_size = 1!\n",[m
     "        x.unsqueeze_(0)\n",[m
[31m-    "        encoder_outputs,hidden = self.encoder(x)\n",[m
[32m+[m[32m    "        encoder_outputs,hidden = self.encoder(x,x_lengths)\n",[m
     "        char_to_input = torch.LongTensor([[2]]).to(device)\n",[m
     "        preds = []\n",[m
     "        while True:\n",[m
[36m@@ -394,7 +379,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 561,[m
[32m+[m[32m   "execution_count": 281,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -403,41 +388,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 377,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [],[m
[31m-   "source": [[m
[31m-    "output,hidden = encoder(x)\n",[m
[31m-    "out_input = torch.LongTensor([[2]]).to(device)\n",[m
[31m-    "preds = []\n",[m
[31m-    "\n",[m
[31m-    "output,hidden = decoder(out_input,hidden)"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 389,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "torch.Size([1, 1])"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 389,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[31m-    }[m
[31m-   ],[m
[31m-   "source": [[m
[31m-    "output = torch.argmax(output)\n",[m
[31m-    "output.unsqueeze_(0).unsqueeze_(0).shape"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 562,[m
[32m+[m[32m   "execution_count": 282,[m
    "metadata": {[m
     "scrolled": true[m
    },[m
[36m@@ -458,7 +409,7 @@[m
        ")"[m
       ][m
      },[m
[31m-     "execution_count": 562,[m
[32m+[m[32m     "execution_count": 282,[m
      "metadata": {},[m
      "output_type": "execute_result"[m
     }[m
[36m@@ -473,7 +424,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 563,[m
[32m+[m[32m   "execution_count": 283,[m
    "metadata": {},[m
    "outputs": [[m
     {[m
[36m@@ -493,45 +444,17 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 564,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [],[m
[31m-   "source": [[m
[31m-    "optimizer = optim.Adam(model.parameters())"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 565,[m
[31m-   "metadata": {},[m
[31m-   "outputs": [[m
[31m-    {[m
[31m-     "data": {[m
[31m-      "text/plain": [[m
[31m-       "{'<sos>': 2, '<eos>': 3, '<pad>': 0, '<unk>': 1, 'M': 4, 'J': 5, 'W': 6, 'D': 7, 'T': 8, 'H': 9, 'L': 10, 'C': 11, 'R': 12, 'S': 13, 'Y': 14, 'I': 15, 'Z': 16, 'K': 17, 'O': 18, 'F': 19, 'G': 20, 'P': 21, 'V': 22, 'U': 23, 'E': 24, 'A': 25, 'N': 26, 'B': 27}"[m
[31m-      ][m
[31m-     },[m
[31m-     "execution_count": 565,[m
[31m-     "metadata": {},[m
[31m-     "output_type": "execute_result"[m
[31m-    }[m
[31m-   ],[m
[31m-   "source": [[m
[31m-    "dataset.transcripts_vocab"[m
[31m-   ][m
[31m-  },[m
[31m-  {[m
[31m-   "cell_type": "code",[m
[31m-   "execution_count": 566,[m
[32m+[m[32m   "execution_count": 284,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[31m-    "criterion = nn.CrossEntropyLoss(ignore_index = 0)\n"[m
[32m+[m[32m    "optimizer = optim.Adam(model.parameters())\n",[m
[32m+[m[32m    "criterion = nn.CrossEntropyLoss(ignore_index = 0)"[m
    ][m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 567,[m
[32m+[m[32m   "execution_count": 271,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -544,12 +467,13 @@[m
     "    for i, batch in enumerate(iterator):\n",[m
     "        \n",[m
     "        x = batch[0].to(device)\n",[m
[31m-    "        y_in = batch[1].to(device)\n",[m
[31m-    "        y_out = batch[2].to(device)\n",[m
[32m+[m[32m    "        x_lengths = batch[1]\n",[m
[32m+[m[32m    "        y_in = batch[2].to(device)\n",[m
[32m+[m[32m    "        y_out = batch[3].to(device)\n",[m
     "        \n",[m
     "        optimizer.zero_grad()\n",[m
     "        \n",[m
[31m-    "        output = model(x, y_in)\n",[m
[32m+[m[32m    "        output = model(x,x_lengths, y_in)\n",[m
     "        #output dim (y_seq_len,batch_size,output_dim)\n",[m
     "        output = output.view(output.shape[0]*output.shape[1],-1)\n",[m
     "        y_out = y_out.view(-1)\n",[m
[36m@@ -572,7 +496,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 568,[m
[32m+[m[32m   "execution_count": 272,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -587,10 +511,11 @@[m
     "        for i, batch in enumerate(iterator):\n",[m
     "\n",[m
     "            x = batch[0].to(device)\n",[m
[31m-    "            y_in = batch[1].to(device)\n",[m
[31m-    "            y_out = batch[2].to(device)\n",[m
[32m+[m[32m    "            x_lengths = batch[1]\n",[m
[32m+[m[32m    "            y_in = batch[2].to(device)\n",[m
[32m+[m[32m    "            y_out = batch[3].to(device)\n",[m
     "            \n",[m
[31m-    "            output = model(x,y_in,0) #turn off teacher forcing\n",[m
[32m+[m[32m    "            output = model(x,x_lengths,y_in,0) #turn off teacher forcing\n",[m
     "            \n",[m
     "            output = output.view(output.shape[0]*output.shape[1],-1)\n",[m
     "            y_out = y_out.view(-1)\n",[m
[36m@@ -605,7 +530,7 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 569,[m
[32m+[m[32m   "execution_count": 273,[m
    "metadata": {},[m
    "outputs": [],[m
    "source": [[m
[36m@@ -620,12 +545,12 @@[m
   },[m
   {[m
    "cell_type": "code",[m
[31m-   "execution_count": 570,[m
[32m+[m[32m   "execution_count": 274,[m
    "metadata": {},[m
    "outputs": [[m
     {[m
      "data": {[m
[31m-      "image/png": "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